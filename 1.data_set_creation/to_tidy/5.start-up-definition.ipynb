{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose\n",
    "\n",
    "Upload\n",
    "\n",
    "The purpose of this notebook is to add a definition of a start up to the affiliation data. There are multiple ways of doing this so the approach taken is as follows:\n",
    "\n",
    "1. Filter affiliations so that only potential start-ups go through the proceeding steps\n",
    "2. Use CH API to retrieve registered company numbers for the matches that were made through CH\n",
    "3. Use company numbers in the batch search functionality of FAME\n",
    "4. Retrieve information from 2010 on revenue\n",
    "5. Exclude the top x'th percentile from candidate start-ups\n",
    "\n",
    "__Resources:__\n",
    "\n",
    "* [FAME](https://library.bath.ac.uk/management/company-information) - access through university library\n",
    "* [Companies House API](https://developer-specs.company-information.service.gov.uk/companies-house-public-data-api/reference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0) Import dependencies and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import os\n",
    "import glob\n",
    "import constants\n",
    "from rapidfuzz import process\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "affils = pd.read_csv(os.getcwd() + r'\\final_data\\scopus_affils_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Filter affiliations\n",
    "\n",
    "* `affil_type = company`\n",
    "* Do not include string matches - if I include Scopus and GRID matches, I will need to do fuzzy matching (on all names - current and previous) before taking the company number to ensure they are the same company\n",
    "* Have an established date after 1990"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corresponds to 11,518 affiliations\n",
    "candidates = affils[(affils['affil_type'] == 'company') &\n",
    "                    (affils['type_source'] != 'string') &\n",
    "                    (affils['est_inc_date'] >= 1990)].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Retrieve registered company numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column to store company number\n",
    "candidates['co_num'] = None\n",
    "candidates['best_score'] = None\n",
    "candidates['best_match'] = None\n",
    "candidates['CH_city'] = None\n",
    "candidates['CH_post_code'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "980 ns ± 51.8 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "def handle_string(string):\n",
    "    '''Function removes ltd, limited, plc from incoming string to\n",
    "    improve matching.'''\n",
    "    \n",
    "    string = string.lower()\n",
    "    if ' ltd' in string:\n",
    "        return string.replace(' ltd', '')\n",
    "    elif ' limited' in string:\n",
    "        return string.replace(' limited', '')\n",
    "    elif ' plc' in string:\n",
    "        return string.replace(' plc', '')\n",
    "    else:\n",
    "        return string\n",
    "    \n",
    "\n",
    "# Test - faster than alternatives tried\n",
    "% timeit handle_string('Strategem PLC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ch_data(query, key, testing=False):\n",
    "    \n",
    "    res = {'co_num': None,\n",
    "           'prev_names': [''],\n",
    "           'address': {'city': None,\n",
    "                       'post_code': None}}\n",
    "    \n",
    "    # URLs\n",
    "    url_search = 'https://api.company-information.service.gov.uk/search/companies'\n",
    "    url_profile = 'https://api.company-information.service.gov.uk/company/?'\n",
    "    \n",
    "    # Retrieve company number and address\n",
    "    connected = False\n",
    "    while not connected:\n",
    "        try:\n",
    "            search_resp = requests.get(url_search, params = {'q': query}, auth = (key, ''))\n",
    "            if search_resp.status_code == 200:\n",
    "                connected = True\n",
    "        except:\n",
    "            time.sleep(10)\n",
    "            pass\n",
    "    search_resp = search_resp.json()\n",
    "    if search_resp['total_results'] == 0:\n",
    "        return res\n",
    "    res['co_num'] = search_resp['items'][0]['company_number']\n",
    "    address = search_resp['items'][0]['address']\n",
    "    \n",
    "    # Address can be None if not provided\n",
    "    if address is not None:\n",
    "        if 'locality' in address:\n",
    "            res['address']['city'] = address['locality']\n",
    "        if 'postal_code' in address:\n",
    "            res['address']['post_code'] = address['postal_code']\n",
    "    \n",
    "    # Find all names - previous and current\n",
    "    connected = False\n",
    "    while not connected:\n",
    "        try:\n",
    "            profile_resp = requests.get(url_profile.replace('?', res['co_num']), auth = (key, ''))\n",
    "            if profile_resp.status_code == 200:\n",
    "                connected = True\n",
    "        except:\n",
    "            time.sleep(10)\n",
    "            pass\n",
    "    names = [profile_resp.json()['company_name']]\n",
    "    if 'previous_company_names' in profile_resp.json():\n",
    "        names += [prev['name'] for prev in profile_resp.json()['previous_company_names']]\n",
    "    \n",
    "    # Remove ltd, limited, plc to improve matching performance\n",
    "    res['prev_names'] = [handle_string(name) for name in names]\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "# Test\n",
    "#% timeit get_ch_data('starlight express limited', constants.API_KEY_CH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 11518/11518 [2:01:48<00:00,  1.58it/s]\n"
     ]
    }
   ],
   "source": [
    "for row in tqdm(candidates.itertuples(), total=candidates.shape[0]):\n",
    "    \n",
    "    if pd.notnull(getattr(row, 'co_num')):\n",
    "        continue\n",
    "    \n",
    "    # Get company number and all previous names\n",
    "    orig_name = handle_string(getattr(row, 'affil_name'))\n",
    "    ret = get_ch_data(orig_name, constants.API_KEY_CH)\n",
    "    \n",
    "    # If match wasn't through CH, check fuzzy matching - CHECK ANYWAY\n",
    "    result = process.extract(orig_name, ret['prev_names'], limit=1)[0]\n",
    "    best_name, best_score = result[0], result[1]\n",
    "    \n",
    "    # If fuzzy match good OR original match was CH >>\n",
    "    # add company number to candidates\n",
    "    candidates.at[row[0], 'co_num'] = ret['co_num']\n",
    "    candidates.at[row[0], 'best_score'] = best_score\n",
    "    candidates.at[row[0], 'best_match'] = best_name\n",
    "    candidates.at[row[0], 'CH_city'] = ret['address']['city']\n",
    "    candidates.at[row[0], 'CH_post_code'] = ret['address']['post_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    11202\n",
       "True       316\n",
       "Name: CH_city, dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates.CH_city.isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates.to_csv('scopus_affils_startup.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = pd.read_csv('scopus_affils_startup.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates.drop(columns=['Unnamed: 0.1'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Create csv files for FAME batch search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11386 out of 11518 will be go to FAME.\n"
     ]
    }
   ],
   "source": [
    "print('{} out of {} will be go to FAME.'.format(candidates[candidates['best_score'] > 85].shape[0], \n",
    "                                               candidates.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new directory\n",
    "os.mkdir('FAME')\n",
    "os.chdir(os.getcwd() + '\\\\FAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates[candidates['best_score'] > 85]['co_num'].to_csv('big_boy.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Load in revenue data\n",
    "\n",
    "Note: There were duplicates in the original data set so there are fewer entries in the resulting FAME search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = glob.glob('*.xlsx')\n",
    "rev = pd.read_excel(fname[0], sheet_name=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop = ['Unnamed: 0', 'Quoted', 'Branch', 'OwnData', 'Woco', 'R/O Full Postcode']\n",
    "rev.drop(columns=drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 2009 rev - 3667 nulls\n",
    "# Last available year - 6169 nulls\n",
    "# 2009 #employees - 3995 nulls\n",
    "rev.rename(columns={'Operating revenue (Turnover)\\nth GBP 2009': '2009_revenue',\n",
    "                    'Turnover\\nth GBP Last avail. yr': 'last_revenue',\n",
    "                    'Number of employees\\n2009': '2009_employees'},\n",
    "          inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change n.a to np.nan\n",
    "for row in rev.itertuples():\n",
    "    idx = getattr(row, 'Index')\n",
    "    rev_2009 = getattr(row, '_6')\n",
    "    \n",
    "    # Change string to np.nan\n",
    "    if rev_2009 == 'n.a.':\n",
    "        rev.at[idx, '2009_revenue'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev = rev.astype({'2009_revenue': float})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Exclude x'th percentile\n",
    "\n",
    "97th percentile corresponds to £42,192.20 in revenue. `idx = 265`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Sort by 20009 revenue\n",
    "rev.sort_values(by=['2009_revenue'], ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find a percentile to cut off - happy with 97th percentile\n",
    "percentile = 97\n",
    "idx = round(rev.shape[0] * ((100 - percentile) / 100))\n",
    "\n",
    "# Add column for start-up\n",
    "rev['start_up'] = None\n",
    "rev.iloc[:idx, -1] = False\n",
    "rev.iloc[idx:, -1] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save new csv\n",
    "rev.to_csv('start-ups.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) Merge files together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop irrelevant columns on revenue df\n",
    "rev = rev[['Registered number', 'start_up']]\n",
    "\n",
    "# Merge on company number\n",
    "rev.rename(columns={'Registered number': 'co_num'}, inplace=True)\n",
    "merged = pd.merge(candidates, rev, how='left', on='co_num')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For companies that didn't match on FAME, set to start-up\n",
    "merged['start_up'].fillna(value=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with affils df\n",
    "affils = pd.read_csv('..\\\\final_data\\\\scopus_affils_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['af_id', 'start_up']\n",
    "final = pd.merge(affils, merged[columns], how='left', on='af_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set start up to False for the rest of affils\n",
    "final['start_up'].fillna(value=False, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save final csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_csv('..\\\\final_data\\\\affils_w_startup.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
